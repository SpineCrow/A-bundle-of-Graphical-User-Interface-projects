{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpineCrow/A-bundle-of-Graphical-User-Interface-projects/blob/main/Final_Source_Code_For_PneuVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below: Application in Gradio using ResNet18"
      ],
      "metadata": {
        "id": "dLYBlNN3H24T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "Fo-rF7ssHTc4",
        "outputId": "c5f61657-9978-4188-eb2e-02e42d091c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://aae17d1bfe645fac03.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aae17d1bfe645fac03.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "\n",
        "# -------------------- MODEL SETUP --------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model.load_state_dict(torch.load(\n",
        "    \"/content/drive/MyDrive/ResNet18 Model and Testing Images/ResNet18model.pth\",\n",
        "    map_location=device\n",
        "))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "class_names = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "\n",
        "#Uncertainty threshold to trigger flagging\n",
        "UNCERTAINTY_THRESHOLD = 0.7\n",
        "# -------------------- DCE FUNCTION --------------------\n",
        "def DCE(pil_image):\n",
        "    gray = np.array(pil_image.convert(\"L\"))\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    cl1 = clahe.apply(gray)\n",
        "    cl1_rgb = cv2.cvtColor(cl1, cv2.COLOR_GRAY2RGB)\n",
        "    return Image.fromarray(cl1_rgb)\n",
        "\n",
        "# -------------------- GRAD-CAM --------------------\n",
        "def generate_heatmap(model, input_tensor, target_class):\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        activations.append(output.detach())\n",
        "\n",
        "    def backward_hook(module, grad_input, grad_output):\n",
        "        gradients.append(grad_output[0].detach())\n",
        "\n",
        "    target_layer = model.layer4[-1].conv2\n",
        "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward + backward\n",
        "    output = model(input_tensor)\n",
        "    model.zero_grad()\n",
        "    class_score = output[0, target_class]\n",
        "    class_score.backward()\n",
        "\n",
        "    grads = gradients[0]\n",
        "    acts = activations[0]\n",
        "    weights = grads.mean(dim=(2, 3), keepdim=True)\n",
        "    cam = (weights * acts).sum(dim=1, keepdim=True)\n",
        "    cam = F.relu(cam)\n",
        "    cam = cam.squeeze().cpu().numpy()\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
        "\n",
        "    forward_handle.remove()\n",
        "    backward_handle.remove()\n",
        "    return cam\n",
        "\n",
        "def overlay_heatmap(pil_image, heatmap):\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "    img = np.array(pil_image.convert(\"RGB\"))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    overlay = cv2.addWeighted(heatmap, 0.4, img, 0.6, 0)\n",
        "    return cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# -------------------- IDENTIFICATION FUNCTION --------------------\n",
        "def IdentifyImage(pil_image, dynamicEnhance):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                             std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    if dynamicEnhance:\n",
        "        pil_image = DCE(pil_image)\n",
        "\n",
        "    input_tensor = transform(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = F.softmax(output, dim=1)[0]\n",
        "        predicted = torch.argmax(probabilities).item()\n",
        "        confidence = probabilities[predicted].item() * 100\n",
        "    # Determining Uncertainty\n",
        "    is_uncertain = confidence < UNCERTAINTY_THRESHOLD\n",
        "    uncertainty_flag = \" (Uncertain, needs review)\" if is_uncertain else \"\"\n",
        "    # Grad-CAM visualization\n",
        "    heatmap = generate_heatmap(model, input_tensor, predicted)\n",
        "    overlay = overlay_heatmap(pil_image.resize((224, 224)), heatmap)\n",
        "    overlay_pil = Image.fromarray(overlay)\n",
        "\n",
        "    result_text = f\"Prediction: {class_names[predicted]} ({confidence:.2f}%) {uncertainty_flag}\"\n",
        "    return result_text, overlay_pil\n",
        "\n",
        "# -------------------- GRADIO INTERFACE --------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"PneuVision Interface - Chest X-Ray Classifier with Grad-CAM using ResNet18\")\n",
        "\n",
        "    with gr.Row():\n",
        "        img = gr.Image(type=\"pil\", image_mode=\"L\", label=\"Upload X-Ray\")\n",
        "        apply_dce_checkbox = gr.Checkbox(label=\"Apply Dynamic Contrast Enhancement (DCE)\", value=True)\n",
        "\n",
        "    output_text = gr.Textbox(label=\"Prediction\")\n",
        "    output_heatmap = gr.Image(label=\"Grad-CAM Heatmap\")\n",
        "\n",
        "    btn = gr.Button(\"Analyze\")\n",
        "    btn.click(IdentifyImage, inputs=[img, apply_dce_checkbox], outputs=[output_text, output_heatmap])\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below: Application in Gradio using ResNet50"
      ],
      "metadata": {
        "id": "SQ4mBxG7HxAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "\n",
        "# -------------------- MODEL SETUP --------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model.load_state_dict(torch.load(\n",
        "    \"/content/drive/MyDrive/ResNet18 Model and Testing Images/ResNet50model_prototype.pth\",\n",
        "    map_location=device\n",
        "))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "class_names = [\"NORMAL\", \"PNEUMONIA\"]\n",
        "\n",
        "#Uncertainty threshold to trigger flagging\n",
        "UNCERTAINTY_THRESHOLD = 0.7\n",
        "# -------------------- DCE FUNCTION --------------------\n",
        "def DCE(pil_image):\n",
        "    gray = np.array(pil_image.convert(\"L\"))\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    cl1 = clahe.apply(gray)\n",
        "    cl1_rgb = cv2.cvtColor(cl1, cv2.COLOR_GRAY2RGB)\n",
        "    return Image.fromarray(cl1_rgb)\n",
        "\n",
        "# -------------------- GRAD-CAM --------------------\n",
        "def generate_heatmap(model, input_tensor, target_class):\n",
        "    gradients = []\n",
        "    activations = []\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        activations.append(output.detach())\n",
        "\n",
        "    def backward_hook(module, grad_input, grad_output):\n",
        "        gradients.append(grad_output[0].detach())\n",
        "\n",
        "    target_layer = model.layer4[-1].conv2\n",
        "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    # Forward + backward\n",
        "    output = model(input_tensor)\n",
        "    model.zero_grad()\n",
        "    class_score = output[0, target_class]\n",
        "    class_score.backward()\n",
        "\n",
        "    grads = gradients[0]\n",
        "    acts = activations[0]\n",
        "    weights = grads.mean(dim=(2, 3), keepdim=True)\n",
        "    cam = (weights * acts).sum(dim=1, keepdim=True)\n",
        "    cam = F.relu(cam)\n",
        "    cam = cam.squeeze().cpu().numpy()\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
        "\n",
        "    forward_handle.remove()\n",
        "    backward_handle.remove()\n",
        "    return cam\n",
        "\n",
        "def overlay_heatmap(pil_image, heatmap):\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "    img = np.array(pil_image.convert(\"RGB\"))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    overlay = cv2.addWeighted(heatmap, 0.4, img, 0.6, 0)\n",
        "    return cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# -------------------- IDENTIFICATION FUNCTION --------------------\n",
        "def IdentifyImage(pil_image, dynamicEnhance):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                             std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    if dynamicEnhance:\n",
        "        pil_image = DCE(pil_image)\n",
        "\n",
        "    input_tensor = transform(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = F.softmax(output, dim=1)[0]\n",
        "        predicted = torch.argmax(probabilities).item()\n",
        "        confidence = probabilities[predicted].item() * 100\n",
        "    # Determining Uncertainty\n",
        "    is_uncertain = confidence < UNCERTAINTY_THRESHOLD\n",
        "    uncertainty_flag = \" (Uncertain, needs review)\" if is_uncertain else \"\"\n",
        "    # Grad-CAM visualization\n",
        "    heatmap = generate_heatmap(model, input_tensor, predicted)\n",
        "    overlay = overlay_heatmap(pil_image.resize((224, 224)), heatmap)\n",
        "    overlay_pil = Image.fromarray(overlay)\n",
        "\n",
        "    result_text = f\"Prediction: {class_names[predicted]} ({confidence:.2f}%) {uncertainty_flag}\"\n",
        "    return result_text, overlay_pil\n",
        "\n",
        "# -------------------- GRADIO INTERFACE --------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"PneuVision Interface - Chest X-Ray Classifier with Grad-CAM using ResNet50\")\n",
        "\n",
        "    with gr.Row():\n",
        "        img = gr.Image(type=\"pil\", image_mode=\"L\", label=\"Upload X-Ray\")\n",
        "        apply_dce_checkbox = gr.Checkbox(label=\"Apply Dynamic Contrast Enhancement (DCE)\", value=True)\n",
        "\n",
        "    output_text = gr.Textbox(label=\"Prediction\")\n",
        "    output_heatmap = gr.Image(label=\"Grad-CAM Heatmap\")\n",
        "\n",
        "    btn = gr.Button(\"Analyze\")\n",
        "    btn.click(IdentifyImage, inputs=[img, apply_dce_checkbox], outputs=[output_text, output_heatmap])\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "OXdyODVPHaaf",
        "outputId": "20109764-e4c0-43a6-9bc3-41bd000c96fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6d9949e53e1688b8ef.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6d9949e53e1688b8ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below: Training Block used for initializing and saving models for future use"
      ],
      "metadata": {
        "id": "HWtb-EAvHiTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms # Import transforms\n",
        "import torchvision.datasets as datasets # Import datasets\n",
        "import torchvision.models as models # Import models\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def UpdateTransform():\n",
        "    return transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # Added a random vertical flip to the dataset\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "transform = UpdateTransform()\n",
        "fixed_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "# Load dataset folders\n",
        "train_dataset = datasets.ImageFolder(root=\"/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train\", transform=transform)\n",
        "val_dataset = datasets.ImageFolder(root=\"/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val\", transform=fixed_transform)\n",
        "test_dataset = datasets.ImageFolder(root=\"/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test\", transform=fixed_transform)\n",
        "\n",
        "# Create loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "#Load neural network\n",
        "#model = models.resnet18(pretrained=True)\n",
        "#model = models.resnet50(pretrained=True) #2nd Model\n",
        "model = models.densenet121(pretrained=True) #3rd Model\n",
        "#Next is DenseNet-121\n",
        "#model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "#Moves workload to GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(device)\n",
        "\n",
        "#Accuracy criteria\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "def TrainModel():\n",
        "  #Trains on entire dataset for x different iterations\n",
        "  num_epochs = 25\n",
        "  #Training loop\n",
        "  for epoch in range(num_epochs):\n",
        "      #Sets model to train, running_loss keeps track of accuracy\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      iteration_count = 0\n",
        "\n",
        "      if (epoch + 1) % 10 == 0:\n",
        "            transform = UpdateTransform()\n",
        "            train_dataset.transform = transform\n",
        "\n",
        "      for images, labels in train_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          iteration_count += 1\n",
        "      print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "      ValidateModel(val_loader)\n",
        "\n",
        "def ValidateModel(loader_set):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for images, labels in loader_set:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  ValidateModel(test_loader)\n",
        "  TrainModel()\n",
        "  ValidateModel(test_loader)\n",
        "  #torch.save(model.state_dict(), \"ResNet18model_prototype.pth\")\n",
        "  #torch.save(model.state_dict(), \"ResNet50model_prototype.pth\")\n",
        "  torch.save(model.state_dict(), \"DenseNet121model_prototype.pth\")\n",
        "  print(\"Model saved\")\n"
      ],
      "metadata": {
        "id": "tRkpdmgpHha_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}